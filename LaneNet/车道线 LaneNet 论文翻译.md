# 车道线 LaneNet 论文翻译

## 近端到端车道检测：一种实例分割方法

<center>摘要</center>
​		现代汽车正在融入越来越多的驾驶员辅助功能，其中包括自动车道保持功能。后者允许汽车在道路车道内正确定位，这对于完全自主汽车的任何后续车道偏离或轨迹规划决策也至关重要。传统的车道检测方法依赖于高度专业化、手工制作的特征和启发式的组合，通常随后是后处理技术，由于道路场景的变化，这些方法计算成本高且易于扩展。最近的方法利用深度学习模型，训练用于像素级车道分割，即使图像中没有标记，因为它们的感受野很大。尽管这些方法具有优势，但它们仅限于检测预定义的固定数量的车道，例如 ego 车道，并且无法应对车道变化。在本文中，我们超越了上述限制，提出将车道检测问题转化为一个实例分割问题，其中每个车道形成自己的实例，可以进行端到端的训练。为了在拟合车道之前对分割车道实例进行参数化，我们进一步建议应用学习的透视变换，以图像为条件，而不是固定的“鸟瞰视图”变换。通过这样做，我们可以确保车道拟合对道路平面变化具有鲁棒性，这与依赖固定预定义变换的现有方法不同。总之，我们提出了一种快速车道检测算法，运行速度为50 fps，可以处理可变数量的车道并应对车道变化。我们在 tuSimple 数据集上验证了我们的方法，并取得了有竞争力的结果。

## 1.INTRODUCTION

​		全自动汽车是当今计算机视觉和机器人技术研究的主要焦点，无论是在学术层面还是在工业层面。每种情况下的目标都是通过使用各种传感器和控制模块，全面了解汽车周围的环境。基于摄像头的车道检测是实现这种环境感知的重要一步，因为它允许汽车在道路车道内正确定位。这对于任何后续车道偏离或轨迹规划决策也至关重要。因此，实时执行精确的基于摄像头的车道检测是实现完全自主驾驶的关键因素。

​		传统的车道检测方法（例如[9]、[15]、[17]、[33]、[35]）依赖高度专业化的手工特征和启发式方法的组合来识别车道段。这些手工制作的线索的流行选择包括基于颜色的特征[7]、结构张量[25]、条形滤波器[34]、脊特征[26]等，这些特征可能与hough变换[23]、[37]和粒子或卡尔曼滤波器[18]、[8]、[34]相结合。在识别出车道段后，采用后处理技术滤除误检，并将路段分组形成最终车道。有关车道检测系统的详细概述，请参阅[3]。一般来说，由于道路场景的变化，这些传统方法很容易出现鲁棒性问题，而这种基于模型的系统很难对这些变化进行建模。

​		最近的方法已经用深度网络取代了手工制作的特征检测器，以学习密集预测，即像素级车道分割。Gopalan等人[11]使用像素层次特征描述符对上下文信息进行建模，并使用boosting算法选择相关上下文特征来检测车道标记。类似地，Kim和Lee[19]将卷积神经网络（CNN）与RANSAC算法相结合，以检测从边缘图像开始的车道。请注意，在他们的方法中，CNN主要用于图像增强，并且仅当道路场景复杂时，例如，它包括路边树木、栅栏或十字路口。Huval等人[16]展示了现有CNN模型如何用于公路驾驶应用，其中一个端到端CNN可执行车道检测和分类。He 等人[13]介绍了双视图CNN（DVCNN），它同时使用前视图和俯视图像来排除错误检测，并分别移除非润滑形状的结构。Li等人[22]建议使用多任务深度卷积网络，该网络侧重于发现几何车道属性，如位置和方向，以及检测车道的递归神经网络（RNN）。最近，Lee等人[21]展示了多任务网络如何在恶劣天气和低照度条件下联合处理车道和道路标记检测和识别。除了上述网络能够更好地分割车道标记[16]外，它们的大感受野还允许它们在图像中没有标记的情况下估计车道。然而，在最后阶段，生成的二元车道分割仍然需要分解到不同的车道实例中。

​		为了解决这个问题，一些方法应用了后处理技术，这些技术再次依赖于启发式，通常由几何特性指导，例如[19]，[12]中所做的。如上所述，由于道路场景的变化，这些启发式方法的计算成本很高，并且容易出现鲁棒性问题。另一项工作[20]将车道检测问题转化为多类分割问题，其中每个车道形成自己的类。通过这样做，网络的输出包含每个车道的解纠缠二进制地图，并且可以以端到端的方式进行训练。尽管有其优点，但该方法仅限于检测预定义的固定数量的车道，即ego车道。此外，由于每条车道都有一个指定的等级，因此无法应对车道的变化。

​		在本文中，我们超越了上述限制，==提出将车道检测问题转换为实例分割问题，其中每个车道在车道类中形成自己的实例。==受密集预测网络在语义分割[24]、[28]、[31]、[6]和实例分割任务[36]、[38]、[30]、[2]、[14]、[5]中的成功启发，==我们设计了一个分支的多任务网络，如[27]用于车道实例分割，由车道分割分支和可端到端训练的车道嵌入分支组成。车道分割分支有两个输出类，背景或车道，而车道嵌入分支将分割的车道像素进一步分解为不同的车道实例。通过将车道检测问题分解为上述两个任务，我们可以充分利用车道分割分支的能力，而不必为不同的车道分配不同的类别。相反，车道嵌入分支（使用聚类损失函数进行训练）将车道id分配给车道分割分支中的每个像素，同时忽略背景像素。通过这样做，我们缓解了车道变化的问题，并且我们可以处理不同数量的车道，这与[20]不同。==

​		==估计车道实例后，即哪些像素属于哪个车道，作为最后一步，我们希望将它们中的每一个转换为参数化描述。为此，曲线拟合算法在文献中得到了广泛应用。常用的模型有三次多项式[32]、[25]、样条曲线[1]或回旋线[10]。为了提高拟合质量，同时保持计算效率，通常使用透视变换将图像转换为“鸟瞰视图”，并在那里执行曲线拟合[39]。通常，变换矩阵在单个图像上计算，并保持固定。但是，如果地平面的形状发生变化（例如，向上倾斜），则此固定变换不再有效。因此，靠近地平线的车道点可能会投影到无穷远处，从而以负面方式影响直线拟合。==

​	==为了纠正这种情况，我们也在拟合曲线之前对图像应用透视变换，但与现有的依赖固定变换矩阵进行透视变换的方法不同，我们训练神经网络来输出变换系数。特别是，神经网络将图像作为输入，并使用针对车道拟合问题定制的损失函数进行优化。所提出方法的一个固有优势是车道拟合对道路平面变化具有鲁棒性，并专门优化以更好地拟合车道。图1显示了我们整个pipeline的概况。==

![1630035543816](D:\yinyuanqi\lanenet-lane-detection-master\paper_pic\Fig1.jpg)

​	系统概述。给定一个输入图像，LaneNet 通过用车道 id 标记每个车道像素来输出车道实例地图。接下来，使用变换矩阵对车道像素进行变换，==变换矩阵由H-Net输出==，H-Net 学习以输入图像为条件的透视变换。对于每个车道，拟合一个三阶多项式，并将车道重新投影到图像上。

​		我们的==贡献==可以总结如下：（1）一个分支的多任务体系结构，将车道检测问题转换为一个实例分割任务，处理车道变化并允许推断任意数量的车道。特别是，车道分割分支输出密集的 per 像素车道段，而车道嵌入分支将分割的车道像素进一步分解为不同的车道实例。（2） 给定输入图像的网络估计透视变换的参数，该变换允许车道拟合对道路平面变化（例如上坡/下坡）具有鲁棒性。

​		论文的其余部分组织如下。第二节介绍了语义和实例车道分割的流程，然后介绍了将分割车道实例转换为参数化线条的方法。第三节介绍了拟建pipeline(综合解决方案)的实验结果。最后，第四节总结了我们的工作。

## 2.METHOD

​		我们训练了一个端到端的神经网络用于车道检测，以解决上述车道切换问题以及车道数量限制。这是通过将车道检测作为一个实例分割问题来实现的。我们称之为LaneNet（见图2）的网络将二元车道分割的优点与为一次实例分割设计的聚类损失函数相结合。在LaneNet的输出中，为每个车道像素分配其对应车道的id。第II-A节对此作了进一步解释。

​		由于LaneNet输出每个车道的像素集合，因此我们仍然必须通过这些像素拟合曲线以获得车道参数化。通常，==车道像素首先使用固定变换矩阵投影到“鸟瞰视图”表示中。但是，由于所有图像的变换参数都是固定的，因此在遇到非平坦地平面（例如在斜坡中）时会出现问题。为了缓解这个问题，我们训练了一个称为H-Net的网络，该网络根据输入图像估计“理想”透视变换的参数。这种转变不一定是典型的“鸟瞰”。相反，它是一种变换，在此变换中，车道可以用低阶多项式进行最佳拟合。第II-B节描述了该程序。==

### $A.LANENET$

​		通过将车道检测视为一个实例分割问题，==对 LaneNet 进行端到端的车道检测训练。这样，网络不受其可检测车道数的限制，并且能够应对车道变化。==实例分割任务由两部分组成，一部分是分割部分，另一部分是聚类部分，下面的部分将对这两部分进行更详细的解释。为了提高性能，在速度和准确性方面[27]，这两个部分在多任务网络中联合训练（见图2）。

​		**二值分割** LaneNet的分割分支（参见图2，底部分支）经过训练以输出二元分割图，指示哪些像素属于车道，哪些不属于车道。为了构建地面真实分割图，我们将所有地面真实车道点连接在一起，形成每个车道的连接线。请注意，我们绘制这些地面真实车道，即使是通过遮挡车辆之类的对象，或者在没有明确的可视车道段（如虚线或褪色车道）的情况下。通过这种方式，网络将学会预测车道位置，即使它们被阻塞或处于不利环境中。采用标准交叉熵损失函数对分割网络进行训练。由于两个类别（车道/背景）高度不平衡，我们采用有界反向类别权重，如[29]所述。

<img src="D:\yinyuanqi\lanenet-lane-detection-master\paper_pic\Fig2.jpg">

​		LaneNet架构。分割分支（底部）经过训练以生成二值车道掩码。嵌入分支（顶部）生成每个车道像素的N维嵌入，因此来自同一车道的嵌入紧密相连，而来自不同车道的嵌入相距很远。为了简单起见，我们展示了每个像素的二维嵌入，它在xy网格中被可视化为颜色贴图（所有像素）和点（仅车道像素）。在使用分割分支中的二进制分割贴图遮罩背景像素后，车道嵌入（蓝色点）聚集在一起并分配给它们的聚类中心（红色点）。

​		**实例分割 ** 为了分离分割分支识别的车道像素，我们训练LaneNet的第二个分支进行车道实例嵌入（见图2，顶部分支）。最流行的检测和分割方法（例如[14]、[38]）对于车道实例分割并不理想，因为边界框检测更适合于紧凑对象，而车道不是。因此，我们使用De Brabandere等人[5]提出的基于距离度量学习的一次性方法，该方法可以轻松地与标准前馈网络集成，并专门为实时应用而设计。

​		通过使用它们的聚类损失函数，训练实例嵌入分支为每个车道像素输出一个嵌入，使得属于同一车道的像素嵌入之间的距离很小，而属于不同车道的像素嵌入之间的距离最大化。通过这样做，相同通道的像素嵌入将聚集在一起，形成每个通道的唯一群集。这是通过引入两个术语实现的，一个是方差项$L_{var}$，它向车道的平均嵌入方向对每个嵌入施加拉力，另一个是距离项，它将簇中心推离彼此。这两个术语都是铰接的：当嵌入物距离簇中心的距离大于$δ_v$时，拉力才起作用；当嵌入物与簇中心的距离小于$δ_d$时，簇中心之间的推力才起作用。$C$表示簇（车道）的数量，$N_c$表示簇$c$中元素的数量，$x_i$像素嵌入，$µ_c$表示簇$c$的平均嵌入，$||·||$表示L2距离，且$[x]_+=max（0，x）$表示铰链，总损耗$L$等于$L_{var}+L_{dist}$，其中：

$$
\begin{cases}L_{var}= \frac{1}{C} \Sigma^{C}_{c=1} \frac{1}{N_c} [||\mu_c-x_i||=\delta_v]^2_+ \\

L_{dist}= \frac{1}{C(C-1)} \Sigma^{C}_{{C_A}=1} \Sigma^{C}_{{c_B}=1,{c_{A}\nep0_C_{B}}}

\end{cases}
$$


![1630120529368](C:\Users\远齐\AppData\Roaming\Typora\typora-user-images\1630120529368.png)



​		一旦网络聚合，车道像素的嵌入将聚集在一起（见图2），使得每个簇彼此之间的距离大于$δ_d$，并且每个簇的半径小于$δ_v$。

​		==聚类是通过一个迭代过程来完成的。通过将δd>6δvin设置为上述损失，可以采用一个随机车道嵌入和半径为2δvt的阈值，以选择属于同一车道的所有嵌入。重复此操作，直到将所有车道嵌入指定给一个车道。为了避免选择一个离群值作为阈值，我们首先使用 meanshift 使其更靠近聚类中心，然后进行阈值处理（见图2）。==

​		网络体系结构LaneNet的体系结构基于编码器-解码器网络 ENet[29] ，该网络因此被修改为两个分支网络。由于ENet的编码器包含的参数比解码器多，因此在两个任务之间完全共享完整的编码器将导致不满意的结果[27]。因此，虽然最初的ENet编码器由三个阶段（阶段1、2、3）组成，但LaneNet仅在两个分支之间共享前两个阶段（1和2），将ENet编码器的阶段3和完整的ENet解码器作为每个独立分支的主干。分割分支的最后一层输出一个单通道图像（二进制分割），而嵌入分支的最后一层输出一个N通道图像，其中N为嵌入维度。这在图2中被示意性地描绘。每个分支的损失项都是==同等加权==的，并通过网络反向传播。

### $B. CURVE \space\space  FITTING  \space USING \space  H-NET$   使用 H-net 进行曲线拟合

​		如前一节所述，LaneNet的输出是每个通道的像素集合。通过原始图像空间中的这些像素拟合多项式并不理想，因为必须借助高阶多项式才能处理弯曲车道。该问题的一个常用解决方案是将图像投影到“鸟瞰图”表示中，其中车道相互平行，因此，曲线车道可以用二阶到三阶多项式拟合。

​		然而，在这些情况下，==变换矩阵H只计算一次，并对所有图像保持固定。通常，这会导致地平面变化下的误差，其中投影到无穷远处的消失点向上或向下移动==（见图3，第二行）。

​		为了解决这个问题，我们训练了一个神经网络H-Net，它具有一个自定义的损失函数：该网络从端到端进行优化，以预测透视变换H的参数，其中变换后的车道点可以用二阶或三阶多项式进行最佳拟合。预测以输入图像为条件，允许网络适应地平面变化下的投影参数，以便车道拟合仍然正确（参见图3的最后一行）。在我们的例子中，H有6个自由度：

![1630134745403](C:\Users\远齐\AppData\Roaming\Typora\typora-user-images\1630134745403.png)

​		放置零是为了强制约束水平线在变换下保持水平。

​		**曲线拟合** 在通过车道像素**P**拟合曲线之前，后者使用 H-Net 输出的变换矩阵进行变换。给定车道像素$pi=[x_i，y_i，1]^T \in P$，变换后的像素$pi^{'}=[x^{'}_i，y^{'}_i，1]^T \in P$等于$H_{p_i}$。

![1630134784403](C:\Users\远齐\AppData\Roaming\Typora\typora-user-images\1630134784403.png)

接下来，使用最小二乘算法通过变换后的像素$P^{'}$拟合n次多项式f（y0）。

​		为了获得给定y位置$y_i$处车道的$x$位置$x^{*}_i$，点$p_i=[-,y_i,1]$被转换为$p^{'}_i=H_{p_{i}}=[-,y^{'}_i,1]^T$，并评估为：$x^{'*}_i=f(y^{'}_i)$。请注意，x-value不重要，并用“-”表示。通过将该点$pi^{'*}=[x^{'*}_i，y^{'*}_i，1]^T \in P$重新投影到原始图像空间，我们得到：$p^{*}_i=H^{-1}P^{'*}_i$,$p^*_i=[x^*_i,y_i,1]^T$。这样，我们可以评估不同y位置的车道。

​		损失函数为了训练 H-Net 输出通过车道像素拟合多项式的最佳变换矩阵，我们构造了以下损失函数。给定N个地面真实道点$p_i=[x_i,y_i,1]^T \in P$ ,我们首先使用H-Net的输出对这些点进行变换：$P^{'}=HP$，$p^{'}_i=[x^{'}_i,y^{'}_i,1]^T \in P$。通过这些投影点，我们使用最小二乘闭式解拟合多项式$f(y^{'})=\alpha y^2 + \beta y^{'} + \gamma$： 

![1630134835011](C:\Users\远齐\AppData\Roaming\Typora\typora-user-images\1630134835011.png)

对于二阶多项式的情况。拟合多项式在每个$y^{'}_i$i位置进行评估，给出 $x^{'*}_i$ 预测。这些预测被投射回：$p^{*}_i=H^{-1}P^{'*}_i,$$p^*_i=[x^*_i,y_i,1]^T$和$p^{'*}_i=[x^{'*}_i,y^{'}_i,1]^T$。损失为：

![1630134850462](C:\Users\远齐\AppData\Roaming\Typora\typora-user-images\1630134850462.png)

由于车道拟合是使用最小二乘算法的闭合形式解进行的，因此损失是可微的。我们使用自动微分来计算梯度。

​		网络体系结构H-Net的网络体系结构有意保持较小，由3x3卷积、batchnorm和ReLUs的连续块构成。使用max pooling layers减少维度，最后添加2个完全连接的层。完整的网络结构见表一。

## 3.RESULTS

A.Dataset

​		目前，tuSimple车道数据集[40]是测试车道检测任务深度学习方法的唯一大型数据集。在良好和中等天气条件下，它包括3626张训练图像和2782张测试图像。它们在不同的白天记录在2车道/3车道/4车道或更多的公路上。注释表示车道在多个离散y位置的X位置。在每个图像上，对当前（ego）车道和左/右车道进行注释，这也是测试集所期望的。

![1630134985698](C:\Users\远齐\AppData\Roaming\Typora\typora-user-images\1630134985698.png)

用于车道拟合的固定单应性和条件单应性（使用H-Net）之间的比较。由于地平面的变化，绿点无法使用固定单应来正确拟合，这可以通过使用H-Net（最后一行）的条件单应来解决。

![1630135032577](C:\Users\远齐\AppData\Roaming\Typora\typora-user-images\1630135032577.png)

​		精度计算为每张图像的平均正确点数，acc=P im Cim SIM，Cim为正确点数，SIM为地面真实点数。当地面真实值和预测点之间的差值小于某个阈值时，该点是正确的。与准确度一起，它们还提供假阳性分数F P=Fpred Npred和假阴性分数F N=Mpred Ngt，其中Fpred为错误预测车道数，Npred为预测车道数，Mpred为错过地面真实车道数，Ngt为所有地面真实车道数。

$B.Setup$

​		**LaneNet** 的训练嵌入维数为4，δv=0.5，δd=3。图像被重新缩放到512x256，网络使用Adam进行训练，批量大小为8，学习率为5e-4，直到收敛。

​		**H-Net** 经过三阶多项式拟合训练，具有尺寸为128x64的输入图像的缩放版本。使用Adam对网络进行训练，批量大小为10，学习速度为5e-5，直至收敛。

​		**速度** 给定512x256的输入分辨率，每像素4维嵌入，并使用三阶多项式拟合，我们的车道检测算法可以运行高达每秒50帧。不同组成部分的详细分类见表四。

$C.Experiments$

​		**插值法** 在表II中，我们使用无变换、固定变换和基于 H-Net 的条件变换计算车道拟合的精度。我们还测量了二阶或三阶多项式拟合之间的差异。在原始图像空间中直接拟合曲线而不进行变换时，这会导致较差的结果；这是意料之中的，因为曲线车道很难使用低阶多项式拟合。

​		通过使用固定变换，我们已经获得了更好的结果，三阶多项式的性能优于二阶多项式。然而，如第IIB节所述，并非所有车道点都可以在固定变换下拟合（另见图3）。当地平面的坡度发生变化时，靠近消失点的点无法正确拟合，因此在MSE测量中被忽略，但仍被视为漏点。

​		使用H-Net生成的变换矩阵，对车道拟合进行了优化，结果优于固定变换的车道拟合。我们不仅可以获得更好的MSE分数，而且使用此方法可以拟合所有点，无论地平面的坡度如何变化。

​		tuSimple结果通过使用LaneNet结合三阶多项式拟合和H-Net的变换矩阵，我们在tuSimple挑战中排名第四，第一个条目之间的差异仅为0.5%。结果见表III。请注意，我们只对tuSimple数据集的训练图像进行了训练，其他条目不清楚，它们的速度性能也不清楚。可视结果如图4所示。

## 4.CONCLUSION

​		在本文中，我们提出了一种以50 fps的速度检测端到端车道的方法。受最近实例分割技术的启发，与其他相关的深度学习方法相比，我们的方法能够检测到可变数量的车道，并能够处理车道变换操作。

​		为了使用低阶多项式对分割车道进行参数化，我们训练了一个网络来生成透视变换的参数，该变换以图像为条件，其中车道拟合是最优的。该网络使用车道拟合的自定义损失函数进行训练。与流行的“鸟瞰视图”方法不同，我们的方法通过相应地调整变换参数，对地平面的坡度变化具有鲁棒性。

致谢：这项工作得到了丰田的支持，并在KU Leuven的跟踪实验室（丰田欧洲自动汽车研究-Leuven）进行。